{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import entity_formatter\n",
    "from entity_tagger import entity_tagger as tagger\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import boto3\n",
    "import traceback\n",
    "import json\n",
    "import dataset_creator\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from labeling_functions import *\n",
    "import snorkel\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "from subprocess import Popen\n",
    "import datetime\n",
    "from snorkel.utils import probs_to_preds\n",
    "import snorkel_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining names for each entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_et_dct = {\n",
    " 0: 'NULL',\n",
    " 1: 'COMPANY NAME',\n",
    " 2: 'DATE',\n",
    " 3: 'PERSON NAME',\n",
    " 4: 'CURRENCY',\n",
    " 5: 'NUMBER',\n",
    " 6: 'PERCENT',\n",
    " 7: 'ROUTE',\n",
    " 8: 'STATE',\n",
    " 9: 'CITY',\n",
    " 10: 'ZIPCODE',\n",
    " 11: 'YEAR',\n",
    " 12: 'OTHER',\n",
    " 13: 'TIME',\n",
    " 14: 'SPECIAL_NUMBER',\n",
    " 15: 'LIST',\n",
    " 16: 'TEXT'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [lf_contains_date_parser,lf_contains_currency,lf_contains_zipcode,\\\n",
    "       lf_contains_state,lf_contains_quntity,lf_contains_phonenumber,lf_contains_SSN,\\\n",
    "       lf_contains_first_name,lf_contains_last_name,lf_contains_last_percent]\n",
    "\n",
    "def get_rid_list():\n",
    "    onlyfiles = [f for f in listdir(\"rids_to_process/\") if isfile(join(\"rids_to_process/\", f))]\n",
    "    onlyfiles = [\"rids_to_process/\" + s for s in onlyfiles]\n",
    "    return onlyfiles\n",
    "\n",
    "def rid_iterator(df):\n",
    "    final_return = pd.DataFrame()\n",
    "    for i,j in df.iterrows():\n",
    "        just_holder = dataset_creator.aggregate_formatted_entities(j.rid)\n",
    "        final_return = final_return.append(pd.DataFrame(just_holder))\n",
    "    return final_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snorkel_labels(frame_to_train):\n",
    "    print(\"==============================Labeling is now started=======================================\")\n",
    "    applier = PandasLFApplier(lfs=lfs)\n",
    "    L_train = applier.apply(df=frame_to_train)\n",
    "    date_parser_coverage, currency_coverage,\\\n",
    "    zipcode_coverage,state_coverage,\\\n",
    "    quntity_coverage,phonenumber_coverage,SSN_coverage,\\\n",
    "    first_name_coverage,last_name_coverage,percent_coverge= (L_train != ABSTAIN).mean(axis=0)\n",
    "    frame_to_train.rename(columns={\"word_id\":\"word_tokens\",\"text\":\"ocr\",\"label_number\":\"preds\"},inplace=True)\n",
    "    print(\"==============================Labeling is now complete=======================================\")\n",
    "    print(\"==============================Summary Stats==================================================\")\n",
    "    print(f\"date_parser_coverage: {date_parser_coverage * 100:.1f}%\")\n",
    "    print(f\"currency_coverage: {currency_coverage * 100:.1f}%\")\n",
    "    print(f\"zipcode_coverage: {zipcode_coverage * 100:.1f}%\")\n",
    "    print(f\"state_coverage: {state_coverage * 100:.1f}%\")\n",
    "    print(f\"quntity_coverage: {quntity_coverage * 100:.1f}%\")\n",
    "    print(f\"phonenumber_coverage: {phonenumber_coverage * 100:.1f}%\")\n",
    "    print(f\"SSN_coverage: {SSN_coverage * 100:.1f}%\")\n",
    "    print(f\"first_name_coverage: {first_name_coverage * 100:.1f}%\")\n",
    "    print(f\"last_name_coverage: {last_name_coverage * 100:.1f}%\")\n",
    "    #print(f\"alpha_number_coverage: {alpha_number_coverage * 100:.1f}%\")\n",
    "    print(f\"percent_coverage: {percent_coverge * 100:.1f}%\")\n",
    "    label_model = LabelModel(cardinality=15, verbose=True)\n",
    "    label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "    frame_to_train[\"label_number\"] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "    frame_to_train.label_number.fillna(0,inplace=True)\n",
    "    frame_to_train['pred_names'] = frame_to_train.label_number.map(inv_et_dct)\n",
    "    return frame_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = get_rid_list()\n",
    "print(\"File paths are below:\")\n",
    "print(paths)\n",
    "for i in paths:\n",
    "    dataset_df = pd.DataFrame()\n",
    "    holder = pd.read_csv(i,names=[\"rid\"])\n",
    "    holder.drop_duplicates(inplace=True)\n",
    "    holder.fillna(\"aa\",axis=0,inplace=True)\n",
    "    holder = holder.head(10)\n",
    "    print(f\"===============Dataset generation is in progress for {i}===============\")\n",
    "    iterator = rid_iterator(holder)\n",
    "    print(\"==============================Dataset generation is now complete======================================\")\n",
    "    print(\"==============================Predicting Labels Now======================================\")\n",
    "    trained_labels = get_snorkel_labels(iterator)\n",
    "    temp = i.split(\"/\")[1]\n",
    "    print(temp)\n",
    "    snorkel_pipeline.start_gathering(str(temp.replace(\"_\",\" \")),trained_labels.rid.unique(),trained_labels)\n",
    "    dataset_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
