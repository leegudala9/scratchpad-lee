{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entity_formatter\n",
    "from entity_tagger import entity_tagger as tagger\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import traceback\n",
    "import snorkel\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('6c1dc98f-6526-4c18-8e4e-f756b2768b9f')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.parse import CoreNLPParser\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize  \n",
    "sner_tagger = StanfordNERTagger('taging_data/english.all.3class.distsim.crf.ser.gz',\n",
    "               'taging_data/stanford-ner.jar',\n",
    "               encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOST IMPORTANT\n",
    "exp_id = \"exp03\" #unique for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = boto3.client(\"ssm\")\n",
    "s3 = boto3.client(\"s3\")\n",
    "root_url = ssm.get_parameter(Name=f\"/account/root-url\")[\"Parameter\"][\"Value\"]\n",
    "apikey = ssm.get_parameter(Name=\"/account/internal-api-key\")[\"Parameter\"][\"Value\"]\n",
    "v1_url = f\"https://remember.{root_url}\"\n",
    "v2_url = f\"https://rememberv2.{root_url}/latest\"\n",
    "acc_owner = ssm.get_parameter(Name=\"/account/owner\")[\"Parameter\"][\"Value\"].upper()\n",
    "headers = {\"x-api-key\": apikey, \"Authorization\": apikey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tagged = []\n",
    "temp_untagged = []\n",
    "page_blobs = []\n",
    "Full_list = []\n",
    "lol = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rememberv2_query(index={}, filters={}):\n",
    "    url = f\"{v2_url}/query\"\n",
    "    results = {}\n",
    "    try:\n",
    "        payload = {\n",
    "            \"Index\": index,\n",
    "            \"Filter\": filters\n",
    "        }\n",
    "        results = json.loads(requests.post(url=url, data=json.dumps(payload), headers=headers).text)[\"Results\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())    \n",
    "    return results\n",
    "\n",
    "\n",
    "def rememberv2_read(objectid):\n",
    "    url = f\"{v2_url}/read\"\n",
    "    results = {}\n",
    "    try:\n",
    "        payload = {\n",
    "            \"ObjectId\": objectid,\n",
    "        }\n",
    "        results = json.loads(requests.post(url=url, data=json.dumps(payload), headers=headers).text)[\"Results\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def remember_recall(rid, datapoint):\n",
    "    url = f\"{v1_url}/recall?_remember_id={rid}&_datapoint={datapoint}\"\n",
    "    res = {}\n",
    "    try:\n",
    "        res = json.loads(requests.get(url=url).text)[\"datapoints\"][0][\"data\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return res\n",
    "    \n",
    "# def make_text_blob(word_ocr):\n",
    "#     text_list = []\n",
    "    \n",
    "#     for i in word_ocr[\"Words\"]:\n",
    "#         text_list.append(i[\"text\"])\n",
    "#     #print(\"\\n\\n\\nBefore Sending it off: \" , text_list)\n",
    "#     return text_list\n",
    "\n",
    "def remember_write(datapoint):\n",
    "    resp_dict = {}\n",
    "    url = f\"{v2_url}/write\"\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            url=url, data=json.dumps(datapoint), headers=headers\n",
    "        )\n",
    "        resp_dict = resp.json()\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return resp_dict\n",
    "\n",
    "\n",
    "def create_datapoint(Type, Fields, TransactionId, Attributes=None):\n",
    "    datapoint = {\n",
    "        \"Type\": Type,\n",
    "        \"Fields\": Fields,\n",
    "        \"TransactionId\": TransactionId,\n",
    "    }\n",
    "    if Attributes != None:\n",
    "        datapoint[\"Attributes\"] = Attributes\n",
    "    return remember_write(datapoint)\n",
    "\n",
    "\n",
    "def remember_memorize(data, rid, datapoint, metadata={}):\n",
    "    url = f\"{v1_url}/memoorize\"\n",
    "    try:\n",
    "        metadata.update({\n",
    "            \"_remember_id\": rid,\n",
    "            \"_datapoint\": datapoint\n",
    "        })\n",
    "        payload = {\n",
    "            \"data\": data,\n",
    "            \"metadata\": metadata \n",
    "        }\n",
    "        resp = requests.post(\n",
    "                url=url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return resp\n",
    "def do_sner_tag(text):\n",
    "    text = text.replace(\"/\",\"-\")\n",
    "    text = text.replace(\"[]\",\"\")\n",
    "    tagged_list = sner_tagger.tag(word_tokenize(text))\n",
    "    return tagged_list\n",
    "def do_spacy_tag(text):\n",
    "    text = text.replace(\"/\",\"-\")\n",
    "    \n",
    "\n",
    "def aggregate_formatted_entities(docid):\n",
    "    temp_dict = {}\n",
    "    try:\n",
    "        recall_txn = rememberv2_read(docid)[0]\n",
    "        txnid = recall_txn[\"TransactionId\"]\n",
    "        file_pages = recall_txn[\"Pages\"]\n",
    "        start = file_pages[0]\n",
    "        doc_pages = list(range(1, len(file_pages)+1))\n",
    "        page_ocrs_ids = {x['ParentIndex']:x['ObjectId'] for x in rememberv2_query({'PageOcr::TransactionId': txnid}, {'ParentIndex': file_pages})}\n",
    "        results = {}\n",
    "        formatted_doc = {}\n",
    "        count = 0\n",
    "        print(\"pages-->\",sorted(page_ocrs_ids.keys()))\n",
    "        for page in sorted(page_ocrs_ids.keys()):\n",
    "            try:\n",
    "                \n",
    "                #print(\"Going on a count: \", count)\n",
    "                count = count+1\n",
    "                words_ocr = rememberv2_query({'Parent': page_ocrs_ids[page]})\n",
    "                parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
    "                blob = tagger.make_blob(parsed_words)\n",
    "                #lol.append(parsed_words)\n",
    "                #print(\"page_number --> \", page)\n",
    "                call_make_df(parsed_words,blob,page,docid)\n",
    "#                 tagged = tagger.handler({'body': json.dumps(words_ocr[0])}, {})\n",
    "#                 find_untagged_words(parsed_words,tagged)\n",
    "#                 formatted = entity_formatter.format_entities(json.loads(tagged['body'])['entities'], page-start+1)['body']\n",
    "#                 results[page] = formatted\n",
    "#                 create_datapoint(\"PageTaggedEntitiesExp\", {\"Entities\": formatted, \"FilePageIndex\": page, \"ExpId\": exp_id}, txnid ,{\"PageTaggedEntitiesExp::DocumentId\": docid})\n",
    "#                 for key in formatted.keys():\n",
    "#                     if key in formatted_doc:\n",
    "#                         formatted_doc[key] = formatted_doc[key] + formatted[key]\n",
    "#                     else:\n",
    "#                         formatted_doc[key] = formatted[key]\n",
    "            except:\n",
    "                print(traceback.format_exc())\n",
    "                pass\n",
    "        return formatted_doc\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        pass\n",
    "def process_tagged_with_text(page):\n",
    "    # extract all named entities\n",
    "    tagged_entities = []\n",
    "    index_count = 0\n",
    "    entity_id = ''\n",
    "    \n",
    "    for term, tag in sentence:\n",
    "        if tag != 'O':\n",
    "            word = term\n",
    "            word_tag = tag\n",
    "            entity_id = uuid.uuid4()\n",
    "            make_entity = {'entity_id': entity_id.hex, 'text': word, 'entity_score': 0.9902280569076538 , 'entity_type': word_tag,'string_index': index_count }                    \n",
    "            index_count = len(term)+index_count+1\n",
    "            tagged_entities.append(make_entity)\n",
    "        else:\n",
    "            index_count = len(term)+index_count+1\n",
    "        \n",
    "    return tagged_entities\n",
    "\n",
    "def find_untagged_words(untagged,tagged):\n",
    "    temp_tagged.append(tagged)\n",
    "    temp_untagged.append(untagged)\n",
    "\n",
    "def get_bucket_key(path):\n",
    "    bucket = path.split('/')[2]\n",
    "    key = path.replace(f'S3://{bucket}/', '')\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_object(path, s3):\n",
    "    bucket, key = get_bucket_key(path)\n",
    "    res = s3.get_object(\n",
    "        Bucket=bucket,\n",
    "        Key=key\n",
    "    )['Body'].read().decode('utf-8')\n",
    "    return res\n",
    "\n",
    "\n",
    "def put_object(path, s3, data):\n",
    "    bucket, key = get_bucket_key(path)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Body=json.dumps(data),\n",
    "        Key=key\n",
    "    )\n",
    "def get_tagged_words(tagged):\n",
    "    list_of_tagged_word_ids = []\n",
    "    for page in tagged:\n",
    "        rip_a_page = json.loads(page[\"body\"])\n",
    "        for entity in rip_a_page[\"entities\"]:\n",
    "            list_of_tagged_word_ids.append(entity[\"word_id\"])\n",
    "    return list_of_tagged_word_ids    \n",
    "    \n",
    "def get_untagged_words(untagged,list_of_tagged_word_ids):\n",
    "    list_of_untagged_word_ids = []\n",
    "    list_of_untagged_entities = []\n",
    "    for page in untagged:\n",
    "        for entity in page:\n",
    "            list_of_untagged_word_ids.append(entity[\"word_id\"])\n",
    "    l3 = [x for x in list_of_untagged_word_ids if x not in list_of_tagged_word_ids]\n",
    "    for word in l3:\n",
    "        for page in untagged:\n",
    "            for entity in page:\n",
    "                if entity[\"word_id\"] == word:\n",
    "                    list_of_untagged_entities.append(entity)\n",
    "    return list_of_untagged_entities,l3\n",
    "    \n",
    "def memorize_results_update_inplace(docid):\n",
    "    formatted_doc = aggregate_formatted_entities(docid)\n",
    "    current_path = remember_recall(docid, '_aggregated_formatted_entities_path')\n",
    "    new_path = current_path.replace(\"FormattedEntities\", f\"FormattedEntities{exp_id}\")\n",
    "    put_object(new_path, s3, formatted_doc)\n",
    "    return new_path\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_make_df(parsed_words,blob,page_num,docid):\n",
    "    for i in parsed_words:\n",
    "        i[\"text_blob\"] = blob\n",
    "        i[\"page_ind\"] = f'page_{page_num+1}'\n",
    "        i[\"rid\"] = docid\n",
    "        i[\"page\"] = page_num+1\n",
    "        full_lits.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lits = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1003_rid_new.csv\",names=[\"rid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1601, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(r'testing_rids.txt', temp.rid.values, fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#temp[f\"{exp_id}_path\"] = temp.apply(lambda row: memorize_results_update_inplace(row[\"rid\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [307, 308, 309, 310, 311]\n",
      "pages--> [651, 652, 653, 654, 655]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [319, 320, 321, 322, 323]\n",
      "pages--> [325, 326, 327, 328]\n",
      "pages--> [411, 412, 413]\n",
      "pages--> [288, 289, 290, 291]\n",
      "pages--> [368, 369, 370, 371]\n",
      "pages--> [240, 241, 242, 243, 244]\n",
      "pages--> [401, 402, 403]\n",
      "pages--> [499, 500, 501, 502]\n",
      "pages--> [324, 325, 326, 327]\n",
      "pages--> [353, 354, 355, 356, 357, 358]\n",
      "pages--> [314, 315, 316, 317]\n",
      "pages--> [475, 476, 477, 478, 479, 480]\n",
      "pages--> [309, 310, 311, 312]\n",
      "pages--> [481, 482, 483, 484, 485]\n",
      "pages--> [269, 270, 271, 272]\n",
      "pages--> [504, 505, 506, 507, 508]\n",
      "pages--> [513, 514, 515, 516]\n",
      "pages--> [426, 427, 428, 429]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [5, 6, 7, 8]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [289, 290, 291, 292, 293]\n",
      "pages--> [344, 345, 346, 347]\n",
      "pages--> [295, 296, 297, 298]\n",
      "pages--> [335, 336, 337, 338]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [6]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [362, 363, 364, 365, 366, 367]\n",
      "pages--> [403, 404, 405, 406]\n",
      "pages--> [781, 782, 783, 784, 785, 786]\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-60a9a78a6558>\", line 114, in aggregate_formatted_entities\n",
      "    parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
      "IndexError: list index out of range\n",
      "\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [260, 261, 262, 263]\n",
      "pages--> [520, 521, 522, 523, 524, 525, 526]\n",
      "pages--> [362, 363, 364, 365, 366]\n",
      "pages--> [0]\n",
      "pages--> [1]\n",
      "pages--> [1]\n",
      "pages--> [1]\n",
      "pages--> [0]\n",
      "pages--> [1]\n",
      "pages--> [0]\n",
      "pages--> [1]\n",
      "pages--> [1]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [6, 7]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5, 6]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3, 4, 5]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [0, 1, 2]\n",
      "pages--> [0, 1, 2, 3, 4]\n",
      "pages--> [0, 1, 2, 3]\n",
      "pages--> [6, 7]\n"
     ]
    }
   ],
   "source": [
    "for i,j in temp.iterrows():\n",
    "    aws_json = aggregate_formatted_entities(j.rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aws_json = aggregate_formatted_entities(\"bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_lits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frame = pd.DataFrame(full_lits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_id</th>\n",
       "      <th>text</th>\n",
       "      <th>string_index</th>\n",
       "      <th>bounding_box</th>\n",
       "      <th>confidence</th>\n",
       "      <th>text_blob</th>\n",
       "      <th>page_ind</th>\n",
       "      <th>rid</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word_1_1</td>\n",
       "      <td>Yellowstone</td>\n",
       "      <td>0</td>\n",
       "      <td>[1139, 84, 1329, 109]</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>page_1</td>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_1_2</td>\n",
       "      <td>Bank</td>\n",
       "      <td>12</td>\n",
       "      <td>[1342, 84, 1420, 109]</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>page_1</td>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>word_1_3</td>\n",
       "      <td>Uniform</td>\n",
       "      <td>17</td>\n",
       "      <td>[691, 150, 936, 201]</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>page_1</td>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>word_1_4</td>\n",
       "      <td>Residential</td>\n",
       "      <td>25</td>\n",
       "      <td>[962, 150, 1308, 201]</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>page_1</td>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word_1_5</td>\n",
       "      <td>Loan</td>\n",
       "      <td>37</td>\n",
       "      <td>[1336, 151, 1486, 201]</td>\n",
       "      <td>0.91</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>page_1</td>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512285</th>\n",
       "      <td>word_8_140</td>\n",
       "      <td>07/05</td>\n",
       "      <td>826</td>\n",
       "      <td>[857, 3094, 918, 3112]</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Continuation Sheet - Schedule of Liabilities B...</td>\n",
       "      <td>page_8</td>\n",
       "      <td>71e84b42-1b13-4dd1-bcd6-cdc8a798c31f</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512286</th>\n",
       "      <td>word_8_141</td>\n",
       "      <td>rev.</td>\n",
       "      <td>832</td>\n",
       "      <td>[927, 3094, 969, 3117]</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Continuation Sheet - Schedule of Liabilities B...</td>\n",
       "      <td>page_8</td>\n",
       "      <td>71e84b42-1b13-4dd1-bcd6-cdc8a798c31f</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512287</th>\n",
       "      <td>word_8_142</td>\n",
       "      <td>6/09</td>\n",
       "      <td>837</td>\n",
       "      <td>[984, 3094, 1038, 3118]</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Continuation Sheet - Schedule of Liabilities B...</td>\n",
       "      <td>page_8</td>\n",
       "      <td>71e84b42-1b13-4dd1-bcd6-cdc8a798c31f</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512288</th>\n",
       "      <td>word_8_143</td>\n",
       "      <td>www_bytesoftware.com</td>\n",
       "      <td>842</td>\n",
       "      <td>[1959, 3097, 2210, 3121]</td>\n",
       "      <td>0.47</td>\n",
       "      <td>Continuation Sheet - Schedule of Liabilities B...</td>\n",
       "      <td>page_8</td>\n",
       "      <td>71e84b42-1b13-4dd1-bcd6-cdc8a798c31f</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512289</th>\n",
       "      <td>word_8_144</td>\n",
       "      <td>B00-685-1008</td>\n",
       "      <td>863</td>\n",
       "      <td>[2225, 3098, 2380, 3117]</td>\n",
       "      <td>0.51</td>\n",
       "      <td>Continuation Sheet - Schedule of Liabilities B...</td>\n",
       "      <td>page_8</td>\n",
       "      <td>71e84b42-1b13-4dd1-bcd6-cdc8a798c31f</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1512290 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word_id                  text  string_index  \\\n",
       "0          word_1_1           Yellowstone             0   \n",
       "1          word_1_2                  Bank            12   \n",
       "2          word_1_3               Uniform            17   \n",
       "3          word_1_4           Residential            25   \n",
       "4          word_1_5                  Loan            37   \n",
       "...             ...                   ...           ...   \n",
       "1512285  word_8_140                 07/05           826   \n",
       "1512286  word_8_141                  rev.           832   \n",
       "1512287  word_8_142                  6/09           837   \n",
       "1512288  word_8_143  www_bytesoftware.com           842   \n",
       "1512289  word_8_144          B00-685-1008           863   \n",
       "\n",
       "                     bounding_box  confidence  \\\n",
       "0           [1139, 84, 1329, 109]        0.91   \n",
       "1           [1342, 84, 1420, 109]        0.92   \n",
       "2            [691, 150, 936, 201]        0.92   \n",
       "3           [962, 150, 1308, 201]        0.91   \n",
       "4          [1336, 151, 1486, 201]        0.91   \n",
       "...                           ...         ...   \n",
       "1512285    [857, 3094, 918, 3112]        0.88   \n",
       "1512286    [927, 3094, 969, 3117]        0.79   \n",
       "1512287   [984, 3094, 1038, 3118]        0.88   \n",
       "1512288  [1959, 3097, 2210, 3121]        0.47   \n",
       "1512289  [2225, 3098, 2380, 3117]        0.51   \n",
       "\n",
       "                                                 text_blob page_ind  \\\n",
       "0        Yellowstone Bank Uniform Residential Loan Appl...   page_1   \n",
       "1        Yellowstone Bank Uniform Residential Loan Appl...   page_1   \n",
       "2        Yellowstone Bank Uniform Residential Loan Appl...   page_1   \n",
       "3        Yellowstone Bank Uniform Residential Loan Appl...   page_1   \n",
       "4        Yellowstone Bank Uniform Residential Loan Appl...   page_1   \n",
       "...                                                    ...      ...   \n",
       "1512285  Continuation Sheet - Schedule of Liabilities B...   page_8   \n",
       "1512286  Continuation Sheet - Schedule of Liabilities B...   page_8   \n",
       "1512287  Continuation Sheet - Schedule of Liabilities B...   page_8   \n",
       "1512288  Continuation Sheet - Schedule of Liabilities B...   page_8   \n",
       "1512289  Continuation Sheet - Schedule of Liabilities B...   page_8   \n",
       "\n",
       "                                          rid  page  \n",
       "0        bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6     1  \n",
       "1        bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6     1  \n",
       "2        bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6     1  \n",
       "3        bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6     1  \n",
       "4        bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6     1  \n",
       "...                                       ...   ...  \n",
       "1512285  71e84b42-1b13-4dd1-bcd6-cdc8a798c31f     8  \n",
       "1512286  71e84b42-1b13-4dd1-bcd6-cdc8a798c31f     8  \n",
       "1512287  71e84b42-1b13-4dd1-bcd6-cdc8a798c31f     8  \n",
       "1512288  71e84b42-1b13-4dd1-bcd6-cdc8a798c31f     8  \n",
       "1512289  71e84b42-1b13-4dd1-bcd6-cdc8a798c31f     8  \n",
       "\n",
       "[1512290 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_frame\n",
    "#training_frame = training_frame[training_frame[\"page\"]<8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frame.to_csv(\"300_final_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tagged_word_ids = get_tagged_words(temp_tagged)\n",
    "list_of_untagged_entities, list_of_untagged_word_ids = get_untagged_words(temp_untagged,list_of_tagged_word_ids)\n",
    "list_of_untagged_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged_word_ids = [ent[\"word_id\"] for ent in list_of_untagged_entities]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Tagging experimentation with other taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_snre_pages = []\n",
    "for blob_by_page in page_blobs:\n",
    "    temp_tag = [sner_tagger.tag(word_tokenize(blob_by_page))]\n",
    "    temp_result_array = process_tagged_with_text(temp_tag)\n",
    "    tagged_snre_pages.append(temp_result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_sner_tagged_entities = tagger.zip_words_entities(temp_untagged[0],tagged_snre_pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparelist = [word[\"word_id\"] for word in zipped_sner_tagged_entities[\"entities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_blobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities(example, show=False):\n",
    "    if show: print(example)\n",
    "    parsedEx = parser(example)\n",
    " \n",
    "    print(\"-------------- entities only ---------------\")\n",
    "    # if you just want the entities and nothing else, you can do access the parsed examples \"ents\" property like this:\n",
    "    ents = list(parsedEx.ents)\n",
    "    tags={}\n",
    "    for entity in ents:\n",
    "        #print(entity.label, entity.label_, ' '.join(t.orth_ for t in entity))\n",
    "        term=' '.join(t.orth_ for t in entity)\n",
    "        if ' '.join(term) not in tags:\n",
    "            tags[term]=[(entity.label, entity.label_)]\n",
    "        else:\n",
    "            tags[term].append((entity.label, entity.label_))\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_check.street_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = datefinder.find_dates(\"If this is an application for joint credit, Borrower and Co-Borrower each agree that we intend to apg_ly for joint credit sign below: DocuSigned by: DocuSigned by —thu'tl M Jolunson. $020312  \")\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
