{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entity_formatter\n",
    "from entity_tagger import entity_tagger as tagger\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.parse import CoreNLPParser\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize  \n",
    "sner_tagger = StanfordNERTagger('taging_data/english.all.3class.distsim.crf.ser.gz',\n",
    "               'taging_data/stanford-ner.jar',\n",
    "               encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MOST IMPORTANT\n",
    "exp_id = \"exp04\" #unique for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = boto3.client(\"ssm\")\n",
    "s3 = boto3.client(\"s3\")\n",
    "root_url = ssm.get_parameter(Name=f\"/account/root-url\")[\"Parameter\"][\"Value\"]\n",
    "apikey = ssm.get_parameter(Name=\"/account/internal-api-key\")[\"Parameter\"][\"Value\"]\n",
    "v1_url = f\"https://remember.{root_url}\"\n",
    "v2_url = f\"https://rememberv2.{root_url}/latest\"\n",
    "acc_owner = ssm.get_parameter(Name=\"/account/owner\")[\"Parameter\"][\"Value\"].upper()\n",
    "headers = {\"x-api-key\": apikey, \"Authorization\": apikey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rememberv2_query(index={}, filters={}):\n",
    "    url = f\"{v2_url}/query\"\n",
    "    results = {}\n",
    "    try:\n",
    "        payload = {\n",
    "            \"Index\": index,\n",
    "            \"Filter\": filters\n",
    "        }\n",
    "        results = json.loads(requests.post(url=url, data=json.dumps(payload), headers=headers).text)[\"Results\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())    \n",
    "    return results\n",
    "\n",
    "\n",
    "def rememberv2_read(objectid):\n",
    "    url = f\"{v2_url}/read\"\n",
    "    results = {}\n",
    "    try:\n",
    "        payload = {\n",
    "            \"ObjectId\": objectid,\n",
    "        }\n",
    "        results = json.loads(requests.post(url=url, data=json.dumps(payload), headers=headers).text)[\"Results\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def remember_recall(rid, datapoint):\n",
    "    url = f\"{v1_url}/recall?_remember_id={rid}&_datapoint={datapoint}\"\n",
    "    res = {}\n",
    "    try:\n",
    "        res = json.loads(requests.get(url=url).text)[\"datapoints\"][0][\"data\"]\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return res\n",
    "    \n",
    "def make_text_blob(word_ocr):\n",
    "    text_list = []\n",
    "    \n",
    "    for i in word_ocr[\"Words\"]:\n",
    "        text_list.append(i[\"text\"])\n",
    "    #print(\"\\n\\n\\nBefore Sending it off: \" , text_list)\n",
    "    return text_list\n",
    "\n",
    "def remember_write(datapoint):\n",
    "    resp_dict = {}\n",
    "    url = f\"{v2_url}/write\"\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            url=url, data=json.dumps(datapoint), headers=headers\n",
    "        )\n",
    "        resp_dict = resp.json()\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return resp_dict\n",
    "\n",
    "\n",
    "def create_datapoint(Type, Fields, TransactionId, Attributes=None):\n",
    "    datapoint = {\n",
    "        \"Type\": Type,\n",
    "        \"Fields\": Fields,\n",
    "        \"TransactionId\": TransactionId,\n",
    "    }\n",
    "    if Attributes != None:\n",
    "        datapoint[\"Attributes\"] = Attributes\n",
    "    return remember_write(datapoint)\n",
    "\n",
    "\n",
    "def remember_memorize(data, rid, datapoint, metadata={}):\n",
    "    url = f\"{v1_url}/memoorize\"\n",
    "    try:\n",
    "        metadata.update({\n",
    "            \"_remember_id\": rid,\n",
    "            \"_datapoint\": datapoint\n",
    "        })\n",
    "        payload = {\n",
    "            \"data\": data,\n",
    "            \"metadata\": metadata \n",
    "        }\n",
    "        resp = requests.post(\n",
    "                url=url, data=json.dumps(payload), headers=headers)\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "    return resp\n",
    "    \n",
    "\n",
    "def aggregate_formatted_entities(docid):\n",
    "    temp_dict = {}\n",
    "    try:\n",
    "        recall_txn = rememberv2_read(docid)[0]\n",
    "        txnid = recall_txn[\"TransactionId\"]\n",
    "        file_pages = recall_txn[\"Pages\"]\n",
    "        start = file_pages[0]\n",
    "        doc_pages = list(range(1, len(file_pages)+1))\n",
    "        page_ocrs_ids = {x['ParentIndex']:x['ObjectId'] for x in rememberv2_query({'PageOcr::TransactionId': txnid}, {'ParentIndex': file_pages})}\n",
    "        results = {}\n",
    "        formatted_doc = {}\n",
    "        for page in sorted(page_ocrs_ids.keys()):\n",
    "            try:\n",
    "                words_ocr = rememberv2_query({'Parent': page_ocrs_ids[page]})\n",
    "                parsed_words = tagger.parse_words(words_ocr[0]['Words'])\n",
    "                print(parsed_words)\n",
    "                temp_cleaned_ =  tagger.make_blob(parsed_words)\n",
    "                words_ids_parsed = sorted(words_ocr[0]['Words'], key=lambda k: int(k['id'].split('_')[-1]))\n",
    "                words_for_frame = [x[\"id\"] for x in words_ids_parsed]\n",
    "                full_list.append({\n",
    "                'rid': docid,\n",
    "                'page_ind': \"page_\"+str(page),\n",
    "                'page': page,\n",
    "                'blob': temp_cleaned_,\n",
    "                'words': words_for_frame\n",
    "                })\n",
    "\n",
    "               \n",
    "                #tagged = tagger.handler({'body': json.dumps(words_ocr[0])}, {})\n",
    "                #formatted = entity_formatter.format_entities(json.loads(tagged['body'])['entities'], page-start+1)['body']\n",
    "                #results[page] = formatted\n",
    "                #create_datapoint(\"PageTaggedEntitiesExp\", {\"Entities\": formatted, \"FilePageIndex\": page, \"ExpId\": exp_id}, txnid ,{\"PageTaggedEntitiesExp::DocumentId\": docid})\n",
    "                #for key in formatted.keys():\n",
    "                #    if key in formatted_doc:\n",
    "                #        formatted_doc[key] = formatted_doc[key] + formatted[key]\n",
    "                #   else:\n",
    "                #        formatted_doc[key] = formatted[key]\n",
    "            except:\n",
    "                print(traceback.format_exc())\n",
    "                pass\n",
    "        #return formatted_doc\n",
    "    except:\n",
    "        print(traceback.format_exc())\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_bucket_key(path):\n",
    "    bucket = path.split('/')[2]\n",
    "    key = path.replace(f'S3://{bucket}/', '')\n",
    "    return bucket, key\n",
    "\n",
    "\n",
    "def get_object(path, s3):\n",
    "    bucket, key = get_bucket_key(path)\n",
    "    res = s3.get_object(\n",
    "        Bucket=bucket,\n",
    "        Key=key\n",
    "    )['Body'].read().decode('utf-8')\n",
    "    return res\n",
    "\n",
    "\n",
    "def put_object(path, s3, data):\n",
    "    bucket, key = get_bucket_key(path)\n",
    "    s3.put_object(\n",
    "        Bucket=bucket,\n",
    "        Body=json.dumps(data),\n",
    "        Key=key\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "def memorize_results_update_inplace(docid):\n",
    "    formatted_doc = aggregate_formatted_entities(docid)\n",
    "    current_path = remember_recall(docid, '_aggregated_formatted_entities_path')\n",
    "    new_path = current_path.replace(\"FormattedEntities\", f\"FormattedEntities{exp_id}\")\n",
    "    put_object(new_path, s3, formatted_doc)\n",
    "    return new_path\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1003_rid_new.csv\",names=[\"rid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b92f37d3-0e81-4ec8-9748-c671367f1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a0a6cdfd-3702-461f-bd0b-55d438c165ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01f10366-dfd8-40cc-848a-a50d0940c563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1d6a9945-0551-41e9-b780-d9e3320a9a3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>286190c6-431f-40d4-b1ba-f462d08da069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>9aa91f9b-539b-4fb0-9855-c6641b0c4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>760c29ca-8303-41fd-adba-5b81ddf527ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>2263515a-5818-44a4-8c82-e87ee2116356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>e2a134ff-160a-41da-bab3-886ca4d9b9f6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1601 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       rid\n",
       "0     bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6\n",
       "1     b92f37d3-0e81-4ec8-9748-c671367f1608\n",
       "2     a0a6cdfd-3702-461f-bd0b-55d438c165ce\n",
       "3     01f10366-dfd8-40cc-848a-a50d0940c563\n",
       "4     1d6a9945-0551-41e9-b780-d9e3320a9a3d\n",
       "...                                    ...\n",
       "1596  286190c6-431f-40d4-b1ba-f462d08da069\n",
       "1597  9aa91f9b-539b-4fb0-9855-c6641b0c4345\n",
       "1598  760c29ca-8303-41fd-adba-5b81ddf527ef\n",
       "1599  2263515a-5818-44a4-8c82-e87ee2116356\n",
       "1600  e2a134ff-160a-41da-bab3-886ca4d9b9f6\n",
       "\n",
       "[1601 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rid    1a256f33-c3c4-43d9-880a-a7e4f009dc35\n",
       "Name: 500, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8063764aa499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maws_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_formatted_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "for i in df.rid.values:\n",
    "    \n",
    "    aws_json = aggregate_formatted_entities(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>page_ind</th>\n",
       "      <th>page</th>\n",
       "      <th>blob</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>page_0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yellowstone Bank Uniform Residential Loan Appl...</td>\n",
       "      <td>[word_1_1, word_1_2, word_1_3, word_1_4, word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>page_1</td>\n",
       "      <td>1</td>\n",
       "      <td>Borrower Yellowstone Bank IV. EMPLOYMENT INFOR...</td>\n",
       "      <td>[word_2_1, word_2_2, word_2_3, word_2_4, word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>page_2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yellowstone Bank VI. ASSETS AND LIABILITIES co...</td>\n",
       "      <td>[word_3_1, word_3_2, word_3_3, word_3_4, word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>page_3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yellowstone Bank LOAN #: 1180303 VII. DETAILS ...</td>\n",
       "      <td>[word_4_1, word_4_2, word_4_3, word_4_4, word_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6</td>\n",
       "      <td>page_4</td>\n",
       "      <td>4</td>\n",
       "      <td>Yellowstone Bank LOAN #: 1180303 Continuation ...</td>\n",
       "      <td>[word_5_1, word_5_2, word_5_3, word_5_4, word_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rid page_ind  page  \\\n",
       "0  bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6   page_0     0   \n",
       "1  bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6   page_1     1   \n",
       "2  bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6   page_2     2   \n",
       "3  bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6   page_3     3   \n",
       "4  bd5ff6ce-f0cf-4b16-8e75-5a25b09b6ad6   page_4     4   \n",
       "\n",
       "                                                blob  \\\n",
       "0  Yellowstone Bank Uniform Residential Loan Appl...   \n",
       "1  Borrower Yellowstone Bank IV. EMPLOYMENT INFOR...   \n",
       "2  Yellowstone Bank VI. ASSETS AND LIABILITIES co...   \n",
       "3  Yellowstone Bank LOAN #: 1180303 VII. DETAILS ...   \n",
       "4  Yellowstone Bank LOAN #: 1180303 Continuation ...   \n",
       "\n",
       "                                               words  \n",
       "0  [word_1_1, word_1_2, word_1_3, word_1_4, word_...  \n",
       "1  [word_2_1, word_2_2, word_2_3, word_2_4, word_...  \n",
       "2  [word_3_1, word_3_2, word_3_3, word_3_4, word_...  \n",
       "3  [word_4_1, word_4_2, word_4_3, word_4_4, word_...  \n",
       "4  [word_5_1, word_5_2, word_5_3, word_5_4, word_...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snorkle_test_df = pd.DataFrame(full_list)\n",
    "snorkle_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "snorkle_test_df.to_csv(\"1003_snorkle_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
